{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data_gen = datagen.flow_from_directory(\n",
    "                clean_data_path,\n",
    "                target_size=(64,128),\n",
    "                color_mode='grayscale',\n",
    "                classes=None,\n",
    "                class_mode='input', # \"input\" will be images identical to input images (mainly used to work with autoencoders)\n",
    "                batch_size=128,\n",
    "                shuffle=True, \n",
    "                seed=42,\n",
    "                save_to_dir=extra_clean_augmented,\n",
    "                save_prefix='augmented_',\n",
    "                save_format='png',\n",
    "                follow_links=False,\n",
    "                subset=None,\n",
    "                interpolation='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 64\n",
    "width = 128\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = 'D:\\\\intern\\\\classified_data\\\\clean_data\\\\extra_clean\\\\extra_clean'\n",
    "extra_clean_augmented = 'D:\\\\intern\\\\classified_data\\\\clean_data\\\\extra_clean_augmented'\n",
    "noisy_15dB_path = 'D:\\\\intern\\\\classified_data\\\\noisy_data\\\\15dB\\\\extra_15dB\\\\extra_15dB'\n",
    "noisy_20dB_path = 'D:\\\\intern\\\\classified_data\\\\noisy_data\\\\20dB\\\\extra_20dB\\\\extra_20dB'\n",
    "noisy_25dB_path = 'D:\\\\intern\\\\classified_data\\\\noisy_data\\\\25dB\\\\extra_25dB\\\\extra_25dB'\n",
    "noisy_30dB_path = 'D:\\\\intern\\\\classified_data\\\\noisy_data\\\\30dB\\\\extra_30dB\\\\extra_30dB'\n",
    "noisy_100dB_path = 'D:\\\\intern\\\\classified_data\\\\noisy_data\\\\100dB\\\\extra_100dB\\\\extra_100dB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_files = os.listdir(clean_data_path)\n",
    "noisy_15dB_files = os.listdir(noisy_15dB_path)\n",
    "noisy_20dB_files = os.listdir(noisy_20dB_path)\n",
    "noisy_25dB_files = os.listdir(noisy_25dB_path)\n",
    "noisy_30dB_files = os.listdir(noisy_30dB_path)\n",
    "noisy_100dB_files = os.listdir(noisy_100dB_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    \n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
    "    brightness_range=None,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.1,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip=False,  \n",
    "    vertical_flip=False, \n",
    "    rescale = 1./255,\n",
    "    preprocessing_function=None,\n",
    "    data_format='channels_last', # means that the images should have shape (samples, height, width, channels)\n",
    "    validation_split=0.0,\n",
    "    dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = np.zeros((len(clean_data_files), height, width, channel), dtype=np.float32)\n",
    "noisy_15dB = np.zeros((len(noisy_15dB_files), height, width, channel), dtype=np.float32)\n",
    "noisy_20dB = np.zeros((len(noisy_20dB_files), height, width, channel), dtype=np.float32)\n",
    "noisy_25dB = np.zeros((len(noisy_25dB_files), height, width, channel), dtype=np.float32)\n",
    "noisy_30dB = np.zeros((len(noisy_30dB_files), height, width, channel), dtype=np.float32)\n",
    "noisy_100dB = np.zeros((len(noisy_100dB_files), height, width, channel), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1510.80it/s]\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for i in tqdm(clean_data_files):\n",
    "    img = cv2.imread(clean_data_path + '\\\\' + i, 1)\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    clean_data[n] = img\n",
    "    n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_gen = datagen.flow(\n",
    "                clean_data, \n",
    "                y=None, \n",
    "                batch_size=8,\n",
    "                shuffle=False,\n",
    "                sample_weight=None,\n",
    "                seed=None,\n",
    "                save_to_dir='extra_clean_augmented',\n",
    "                save_prefix='augmented_',\n",
    "                save_format='png',\n",
    "                subset=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `array_to_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f610cd9a28e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_data_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[0;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_to_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m                 fname = '{prefix}_{index}_{hash}.{format}'.format(\n\u001b[0;32m    161\u001b[0m                     \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36marray_to_img\u001b[1;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \"\"\"\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpil_image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         raise ImportError('Could not import PIL.Image. '\n\u001b[0m\u001b[0;32m    246\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m    247\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `array_to_img` requires PIL."
     ]
    }
   ],
   "source": [
    "clean_data_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\evrn_\\anaconda3\\envs\\tensorflow\\lib\\site-packages (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b7f01c2f8cfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
